{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T11:40:57.777063400Z",
     "start_time": "2026-01-10T11:37:46.674875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from datasets import load_dataset\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "\n",
    "# TensorFlow / Keras for MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from PIL import Image\n",
    "\n",
    "# --- 1. SETTINGS ---\n",
    "TARGET_CLASSES = [\n",
    "    \"Apple\", \"Banana\", \"Orange\", \"Mango\", \"Grapes\",\n",
    "    \"Pineapple\", \"Watermelon\", \"Pomegranate\", \"Strawberry\", \"Lemon\"\n",
    "]\n",
    "\n",
    "# MobileNetV2 expects images to be at least 32x32.\n",
    "# Standard is 224x224, but 96x96 or 128x128 works well for speed.\n",
    "IMG_SIZE = (96, 96)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "def get_data_and_extract_features():\n",
    "    print(\"Loading Dataset from Hugging Face...\")\n",
    "    dataset = load_dataset(\"ysif9/fruit-recognition\")\n",
    "\n",
    "    # Filter Classes\n",
    "    all_class_names = dataset['train'].features['label'].names\n",
    "    target_ids = [all_class_names.index(name) for name in TARGET_CLASSES if name in all_class_names]\n",
    "    dataset = dataset.filter(lambda example: example['label'] in target_ids)\n",
    "\n",
    "    # --- SETUP MOBILENETV2 ---\n",
    "    print(\"Loading MobileNetV2 (Pre-trained on ImageNet)...\")\n",
    "    # include_top=False removes the final classification layer, giving us raw features\n",
    "    # pooling='avg' averages the features into a 1D vector (size 1280)\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3), pooling='avg')\n",
    "\n",
    "    def process_and_extract(split_name):\n",
    "        print(f\"Processing {split_name} data...\")\n",
    "        images = []\n",
    "        labels = []\n",
    "\n",
    "        # Iterate through dataset\n",
    "        ds_split = dataset[split_name]\n",
    "\n",
    "        # We process in batches to save RAM, but for simplicity in this script\n",
    "        # let's prep the array first.\n",
    "        raw_images_batch = []\n",
    "\n",
    "        for i, example in enumerate(ds_split):\n",
    "            img = example['image']\n",
    "            if img.mode != 'RGB': img = img.convert('RGB')\n",
    "            img = img.resize(IMG_SIZE)\n",
    "\n",
    "            # Convert to array and preprocess for MobileNet\n",
    "            img_array = img_to_array(img)\n",
    "            img_array = preprocess_input(img_array) # scales to [-1, 1]\n",
    "\n",
    "            raw_images_batch.append(img_array)\n",
    "            labels.append(example['label'])\n",
    "\n",
    "            # Extract in chunks of 500 to keep memory low\n",
    "            if len(raw_images_batch) >= 500:\n",
    "                batch_arr = np.array(raw_images_batch)\n",
    "                features = base_model.predict(batch_arr, verbose=0)\n",
    "                images.append(features)\n",
    "                raw_images_batch = [] # clear memory\n",
    "                print(f\"  Processed {i+1}/{len(ds_split)} images...\", end='\\r')\n",
    "\n",
    "        # Process remaining\n",
    "        if raw_images_batch:\n",
    "            batch_arr = np.array(raw_images_batch)\n",
    "            features = base_model.predict(batch_arr, verbose=0)\n",
    "            images.append(features)\n",
    "\n",
    "        # Concatenate all batches\n",
    "        X = np.vstack(images)\n",
    "        y = np.array(labels)\n",
    "        print(f\"\\nFinished {split_name}. Shape: {X.shape}\")\n",
    "        return X, y\n",
    "\n",
    "    X_train, y_train = process_and_extract('train')\n",
    "    X_test, y_test = process_and_extract('test')\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# --- MAIN EXECUTION ---\n",
    "X_train, y_train, X_test, y_test = get_data_and_extract_features()"
   ],
   "id": "d200813438f821f3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Dataset from Hugging Face...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Filter:   0%|          | 0/25659 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "85b3fa17209c4ad3976d05ffca8a4201"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Filter:   0%|          | 0/6821 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c88ad21b476e4675bcb9857be8f30c7d"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Filter:   0%|          | 0/7070 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5ba88dcf46d14fe8b6e1e75a5a97e68c"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MobileNetV2 (Pre-trained on ImageNet)...\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_96_no_top.h5\n",
      "\u001B[1m9406464/9406464\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 0us/step\n",
      "Processing train data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yousi\\PycharmProjects\\fruit-detection\\.venv\\lib\\site-packages\\PIL\\Image.py:1034: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 17000/17203 images...\r\n",
      "Finished train. Shape: (17203, 1280)\n",
      "Processing test data...\n",
      "  Processed 5000/5077 images...\r\n",
      "Finished test. Shape: (5077, 1280)\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T11:42:23.394478700Z",
     "start_time": "2026-01-10T11:42:21.665738400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Encode Labels\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_test_encoded = le.transform(y_test)\n",
    "\n",
    "# Get Names\n",
    "temp_ds = load_dataset(\"ysif9/fruit-recognition\", split=\"train[:1]\")\n",
    "all_names = temp_ds.features['label'].names\n",
    "encoded_target_names = [all_names[i] for i in le.classes_]\n",
    "\n",
    "print(\"\\n---------------------------------------------------\")\n",
    "print(f\"New Feature Shape: {X_train.shape}\")\n",
    "print(\"(Notice it is now (N, 1280) instead of (N, 12288) or similar pixels)\")\n",
    "print(\"---------------------------------------------------\\n\")"
   ],
   "id": "78faf81b03104be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------\n",
      "New Feature Shape: (17203, 1280)\n",
      "(Notice it is now (N, 1280) instead of (N, 12288) or similar pixels)\n",
      "---------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T11:45:01.156680600Z",
     "start_time": "2026-01-10T11:44:04.663886200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#SVM\n",
    "model = SVC(gamma='auto', kernel='linear')\n",
    "model.fit(X_train, y_train_encoded)\n",
    "y_pred = model.predict(X_test)\n",
    "precision = metrics.accuracy_score(y_pred, y_test_encoded) * 100\n",
    "print(\"Accuracy with SVM: {0:.2f}%\".format(precision))\n",
    "\n",
    "#K-NN\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "model.fit(X_train, y_train_encoded)\n",
    "y_pred = model.predict(X_test)\n",
    "precision = metrics.accuracy_score(y_pred, y_test_encoded) * 100\n",
    "print(\"Accuracy with K-NN: {0:.2f}%\".format(precision))\n",
    "\n",
    "#DECISION TREE\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train,y_train_encoded)\n",
    "y_pred = model.predict(X_test)\n",
    "precision = metrics.accuracy_score(y_pred, y_test_encoded) * 100\n",
    "print(\"Accuracy with Decision Tree: {0:.2f}%\".format(precision))"
   ],
   "id": "8d5e78196d8752b5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with SVM: 84.60%\n",
      "Accuracy with K-NN: 80.74%\n",
      "Accuracy with Decision Tree: 60.35%\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T11:45:42.403207700Z",
     "start_time": "2026-01-10T11:45:38.530231400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# loss='hinge' makes this behave exactly like a Linear SVM\n",
    "# n_jobs=-1 uses all your processor cores\n",
    "sgd_model = SGDClassifier(loss='hinge', penalty='l2', n_jobs=-1, random_state=42)\n",
    "\n",
    "print(\"Training SGD (Linear SVM approximation)...\")\n",
    "sgd_model.fit(X_train, y_train_encoded) # Make sure to use encoded labels if available, or y_train\n",
    "\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "acc = accuracy_score(y_test_encoded, y_pred) * 100\n",
    "print(f\"Accuracy with SGD-SVM: {acc:.2f}%\")"
   ],
   "id": "a3925491f41a19d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SGD (Linear SVM approximation)...\n",
      "Accuracy with SGD-SVM: 83.28%\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T11:46:00.523726500Z",
     "start_time": "2026-01-10T11:45:50.125404800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Create a pipeline: PCA first, then SVM\n",
    "# n_components=100 compresses the image from 12,288 features to just 100 features\n",
    "# This makes the SVM run 100x faster.\n",
    "pca = PCA(n_components=100, whiten=True, random_state=42)\n",
    "svc = SVC(kernel='rbf', class_weight='balanced', C=10, gamma=0.01) # RBF is usually better than Linear\n",
    "\n",
    "svc_pca_model = make_pipeline(pca, svc)\n",
    "\n",
    "print(\"Training PCA + SVM...\")\n",
    "# This should take about 1-2 minutes instead of hours\n",
    "svc_pca_model.fit(X_train, y_train_encoded)\n",
    "\n",
    "y_pred = svc_pca_model.predict(X_test)\n",
    "acc = accuracy_score(y_test_encoded, y_pred) * 100\n",
    "print(f\"Accuracy with PCA+SVM: {acc:.2f}%\")"
   ],
   "id": "1e765fd1e949a45e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training PCA + SVM...\n",
      "Accuracy with PCA+SVM: 87.71%\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T11:50:18.747798900Z",
     "start_time": "2026-01-10T11:47:04.244150100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "xgb_cls = xgb.XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    eval_metric='mlogloss',\n",
    "    # use_label_encoder=False,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Training XGBoost...\")\n",
    "xgb_cls.fit(X_train, y_train_encoded)\n",
    "\n",
    "y_pred = xgb_cls.predict(X_test)\n",
    "acc = accuracy_score(y_test_encoded, y_pred) * 100\n",
    "print(f\"Accuracy with XGBoost: {acc:.2f}%\")"
   ],
   "id": "36c60c55a6f9a002",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yousi\\PycharmProjects\\fruit-detection\\.venv\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [13:47:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with XGBoost: 83.75%\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-10T11:53:11.596286400Z",
     "start_time": "2026-01-10T11:51:02.024074200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# --- 5. GRID SEARCH CV FOR RANDOM FOREST ---\n",
    "print(\"\\n=== GridSearchCV (Random Forest) ===\")\n",
    "print(\"Starting Grid Search... this may take a while depending on your CPU.\")\n",
    "\n",
    "# Define the parameter grid\n",
    "# Note: Keeping the grid relatively small to save execution time.\n",
    "# You can expand these lists for better tuning.\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "# cv=3 means 3-fold cross-validation\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    verbose=2,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "grid_search.fit(X_train, y_train_encoded)\n",
    "time_taken = time.time() - start_time\n",
    "\n",
    "print(f\"\\nGrid Search complete in {time_taken:.2f} seconds.\")\n",
    "print(f\"Best Parameters found: {grid_search.best_params_}\")\n",
    "print(f\"Best Cross-Val Accuracy: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Predict using the best model found\n",
    "best_rf = grid_search.best_estimator_\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "final_acc = accuracy_score(y_test_encoded, y_pred_rf)\n",
    "\n",
    "print(f\"\\nTest Set Accuracy (Best RF): {final_acc:.4f}\")\n",
    "print(classification_report(y_test_encoded, y_pred_rf, target_names=encoded_target_names, zero_division=0))"
   ],
   "id": "e3df1d5219eec056",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GridSearchCV (Random Forest) ===\n",
      "Starting Grid Search... this may take a while depending on your CPU.\n",
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
      "\n",
      "Grid Search complete in 129.41 seconds.\n",
      "Best Parameters found: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best Cross-Val Accuracy: 0.8363\n",
      "\n",
      "Test Set Accuracy (Best RF): 0.8202\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Apple       0.81      0.70      0.75       435\n",
      "      Banana       0.83      0.91      0.87       484\n",
      "      Grapes       0.82      0.89      0.85       426\n",
      "       Lemon       0.78      0.56      0.65       408\n",
      "       Mango       0.77      0.62      0.69       346\n",
      "      Orange       0.72      0.87      0.79       872\n",
      "   Pineapple       0.86      0.86      0.86       373\n",
      " Pomegranate       0.86      0.89      0.87       787\n",
      "  Strawberry       0.93      0.85      0.89       419\n",
      "  Watermelon       0.91      0.87      0.89       527\n",
      "\n",
      "    accuracy                           0.82      5077\n",
      "   macro avg       0.83      0.80      0.81      5077\n",
      "weighted avg       0.82      0.82      0.82      5077\n",
      "\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d91bd8e13c4bd3fb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
